{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-23T10:52:29.415771Z","iopub.status.busy":"2023-04-23T10:52:29.415347Z","iopub.status.idle":"2023-04-23T10:52:29.459323Z","shell.execute_reply":"2023-04-23T10:52:29.457906Z","shell.execute_reply.started":"2023-04-23T10:52:29.415732Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/amazon-product-length-prediction-dataset/dataset/sample_submission.csv\n","/kaggle/input/amazon-product-length-prediction-dataset/dataset/train.csv\n","/kaggle/input/amazon-product-length-prediction-dataset/dataset/test.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-23T10:52:34.687384Z","iopub.status.busy":"2023-04-23T10:52:34.686637Z","iopub.status.idle":"2023-04-23T10:52:44.715123Z","shell.execute_reply":"2023-04-23T10:52:44.713776Z","shell.execute_reply.started":"2023-04-23T10:52:34.687341Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-23T10:52:51.570450Z","iopub.status.busy":"2023-04-23T10:52:51.569616Z","iopub.status.idle":"2023-04-23T10:53:45.868031Z","shell.execute_reply":"2023-04-23T10:53:45.866807Z","shell.execute_reply.started":"2023-04-23T10:52:51.570407Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('/kaggle/input/amazon-product-length-prediction-dataset/dataset/train.csv')\n","test_df = pd.read_csv('/kaggle/input/amazon-product-length-prediction-dataset/dataset/test.csv')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-23T10:53:57.290155Z","iopub.status.busy":"2023-04-23T10:53:57.289321Z","iopub.status.idle":"2023-04-23T10:53:58.801361Z","shell.execute_reply":"2023-04-23T10:53:58.800038Z","shell.execute_reply.started":"2023-04-23T10:53:57.290105Z"},"trusted":true},"outputs":[],"source":["# Split the dataset into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_df['TITLE'], train_df['PRODUCT_LENGTH'], test_size=0.3, random_state=42)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-23T10:54:06.112557Z","iopub.status.busy":"2023-04-23T10:54:06.112111Z","iopub.status.idle":"2023-04-23T12:10:32.120180Z","shell.execute_reply":"2023-04-23T12:10:32.118777Z","shell.execute_reply.started":"2023-04-23T10:54:06.112505Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","49213/49213 [==============================] - 470s 9ms/step - loss: 3899.3774 - val_loss: 2973.0220\n","Epoch 2/10\n","49213/49213 [==============================] - 427s 9ms/step - loss: 3746.7666 - val_loss: 2936.4260\n","Epoch 3/10\n","49213/49213 [==============================] - 435s 9ms/step - loss: 3720.4790 - val_loss: 2919.7666\n","Epoch 4/10\n","49213/49213 [==============================] - 430s 9ms/step - loss: 3703.7656 - val_loss: 2906.6284\n","Epoch 5/10\n","49213/49213 [==============================] - 433s 9ms/step - loss: 3689.5017 - val_loss: 2895.8367\n","Epoch 6/10\n","49213/49213 [==============================] - 436s 9ms/step - loss: 3678.4131 - val_loss: 2888.1663\n","Epoch 7/10\n","49213/49213 [==============================] - 436s 9ms/step - loss: 3668.2166 - val_loss: 2880.1763\n","Epoch 8/10\n","49213/49213 [==============================] - 437s 9ms/step - loss: 3659.1851 - val_loss: 2873.6855\n","Epoch 9/10\n","49213/49213 [==============================] - 428s 9ms/step - loss: 3650.5830 - val_loss: 2868.0251\n","Epoch 10/10\n","49213/49213 [==============================] - 443s 9ms/step - loss: 3643.8518 - val_loss: 2864.1826\n","Mean absolute error on validation set: 2864.1826171875\n"]}],"source":["# Convert the titles to sequences of integers\n","tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts([str(x) for x in X_train])\n","X_train = tokenizer.texts_to_sequences([str(x) for x in X_train])\n","X_val = tokenizer.texts_to_sequences([str(x) for x in X_val])\n","\n","# Pad the sequences to a fixed length\n","max_length = 50\n","X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n","X_val = pad_sequences(X_val, maxlen=max_length, padding='post', truncating='post')\n","\n","# Define the model\n","model = Sequential()\n","model.add(Embedding(input_dim=5000, output_dim=32, input_length=max_length))\n","model.add(LSTM(units=32))\n","model.add(Dense(units=1, activation='linear'))\n","\n","# Compile the model\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss='mean_absolute_error')\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_val, y_val))\n","\n","# Evaluate the model on the validation set\n","score = model.evaluate(X_val, y_val, verbose=0)\n","print(\"Mean absolute error on validation set:\", score)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-23T12:14:51.478762Z","iopub.status.busy":"2023-04-23T12:14:51.478389Z","iopub.status.idle":"2023-04-23T12:16:28.856215Z","shell.execute_reply":"2023-04-23T12:16:28.854900Z","shell.execute_reply.started":"2023-04-23T12:14:51.478728Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["stmt 7\n","22961/22961 [==============================] - 70s 3ms/step\n"]}],"source":["print(\"stmt 7\")\n","new_titles = test_df['TITLE'].astype(str)\n","new_seqs = tokenizer.texts_to_sequences(new_titles)\n","new_padded_seqs = pad_sequences(new_seqs, maxlen=max_length, padding='post', truncating='post')\n","predictions = model.predict(new_padded_seqs)\n","predictions = np.array(predictions).flatten()\n","output = pd.DataFrame({'PRODUCT_ID' : test_df['PRODUCT_ID'], 'PRODUCT_LENGTH' : predictions})\n","output.to_csv('submission.csv', index = False)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-22T17:28:04.745236Z","iopub.status.busy":"2023-04-22T17:28:04.744847Z","iopub.status.idle":"2023-04-22T17:28:04.856111Z","shell.execute_reply":"2023-04-22T17:28:04.854173Z","shell.execute_reply.started":"2023-04-22T17:28:04.745204Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1238477137.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TITLE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m                 raise ValueError(\n\u001b[0;32m-> 2376\u001b[0;31m                     \u001b[0;34m\"Unexpected result of `predict_function` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2377\u001b[0m                     \u001b[0;34m\"(Empty batch_outputs). Please use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m                     \u001b[0;34m\"`Model.compile(..., run_eagerly=True)`, or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."]}],"source":["# X_test = tokenizer.texts_to_sequences(test_df['TITLE'])\n","# X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')\n","# id_test = test_df['PRODUCT_ID'].astype(str) # convert to string\n","# #y_pred = model.predict([X_test, id_test])\n","# import tensorflow as tf\n","# tf.config.run_functions_eagerly(True)\n","\n","# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","# y_pred = model.predict([X_test, id_test])\n","\n","X_test = tokenizer.texts_to_sequences(test_df['TITLE'])\n","X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')\n","y_pred = model.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the predictions to a CSV file\n","output_df = pd.DataFrame({'PRODUCT_ID': id_test, 'PREDICTED_LENGTH': y_pred.flatten()})\n","output_df.to_csv('predictions.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
